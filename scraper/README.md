# ğŸš— Alto Carwash - Web Scraper

Herramienta automatizada para recopilar informaciÃ³n de autolavados en Chile, especÃ­ficamente en la RegiÃ³n Metropolitana, comuna de MaipÃº.

## ğŸ¯ Objetivo

Este scraper recopila datos de autolavados desde mÃºltiples fuentes:
- âœ… **Yapo.cl** - Clasificados chilenos
- âœ… **Google Maps** - Con API key (recomendado)
- âœ… **Google Maps** - Con Puppeteer (sin API key)
- ğŸ”„ **Extensible** - FÃ¡cil agregar nuevas fuentes

## ğŸ“‹ Datos Recopilados

Para cada autolavado se obtiene:
- Nombre del negocio
- DirecciÃ³n completa
- Comuna y regiÃ³n
- TelÃ©fono de contacto
- Email (si estÃ¡ disponible)
- Sitio web
- DescripciÃ³n
- Servicios ofrecidos
- Precios (cuando estÃ¡n disponibles)
- Rating/calificaciÃ³n
- Cantidad de reseÃ±as
- Coordenadas (latitud/longitud)
- Horarios de atenciÃ³n
- ImÃ¡genes
- Fuente de los datos

## ğŸš€ InstalaciÃ³n

```bash
# 1. Navegar a la carpeta del scraper
cd scraper

# 2. Instalar dependencias
npm install

# 3. Configurar variables de entorno
cp .env.example .env
# Edita .env con tus configuraciones
```

## âš™ï¸ ConfiguraciÃ³n

Edita el archivo `.env`:

```env
# Opcional: Google Maps API Key para mejores resultados
GOOGLE_MAPS_API_KEY=tu_api_key_aqui

# ConfiguraciÃ³n de bÃºsqueda
REGION=RegiÃ³n Metropolitana
COMUNA=MaipÃº
SEARCH_QUERY=autolavado

# Opciones
MAX_RESULTS=50
DELAY_BETWEEN_REQUESTS=2000
```

### ğŸ—ï¸ Obtener Google Maps API Key (Opcional pero Recomendado)

1. Ve a [Google Cloud Console](https://console.cloud.google.com/)
2. Crea un nuevo proyecto
3. Habilita **Places API**
4. Crea credenciales â†’ API Key
5. Copia la key al archivo `.env`

**Nota**: Google ofrece $200 USD de crÃ©dito mensual gratuito.

## ğŸ’» Uso

### OpciÃ³n 1: Scraping BÃ¡sico (Yapo.cl)
```bash
npm start
```

### OpciÃ³n 2: Con Google Maps API
```bash
# Configura GOOGLE_MAPS_API_KEY en .env
npm start
```

### OpciÃ³n 3: Con Puppeteer (mÃ¡s datos, mÃ¡s lento)
```bash
npm start -- --puppeteer
```

### OpciÃ³n 4: Scraping EspecÃ­fico
```bash
# Solo Yapo
npm run scrape:yapo

# Solo Google Maps
npm run scrape:google

# Todo junto
npm run scrape:all
```

## ğŸ“¤ Formatos de ExportaciÃ³n

Los datos se exportan automÃ¡ticamente en 4 formatos:

### 1. **JSON** (`carwashes.json`)
```json
[
  {
    "name": "AutoLavado Express",
    "address": "Av. Pajaritos 1234, MaipÃº",
    "phone": "+56912345678",
    "services": ["Lavado exterior", "Encerado"],
    "rating": 4.5
  }
]
```

### 2. **Excel** (`carwashes.xlsx`)
- Ideal para anÃ¡lisis en Excel
- Una fila por autolavado
- Todas las columnas organizadas

### 3. **CSV** (`carwashes.csv`)
- Compatible con cualquier software
- Importable a Google Sheets

### 4. **SQL** (`insert_carwashes.sql`)
- Scripts SQL bÃ¡sicos (deprecado)
- âš ï¸ **Recomendado**: Usar el importador de Prisma en su lugar

## ğŸ“¥ **NUEVO: ImportaciÃ³n Directa a Base de Datos**

### Usar Prisma Importer (Recomendado)

```bash
# 1. Configurar conexiÃ³n a la base de datos
# Copia DATABASE_URL y DIRECT_URL de backend/.env a scraper/.env

# 2. Generar Prisma Client
npm run prisma:generate

# 3. Importar datos de muestra (primeros 5)
npm run import:sample

# 4. Importar todos los datos
npm run import

# 5. Ver estadÃ­sticas
npm run import -- --stats

# 6. Limpiar datos scrapeados
npm run import -- --clean
```

ğŸ“š **GuÃ­a completa**: Lee [IMPORT_GUIDE.md](./IMPORT_GUIDE.md) para mÃ¡s detalles

### Ventajas del Importador Prisma

âœ… **Seguro**: Usa Prisma Client, no SQL raw  
âœ… **Completo**: Crea Users, Providers y Services automÃ¡ticamente  
âœ… **Inteligente**: Detecta y omite duplicados  
âœ… **ValidaciÃ³n**: Valida datos antes de insertar  
âœ… **Transaccional**: Rollback automÃ¡tico en caso de errores  

## ğŸ“ Estructura de Salida

```
output/
â”œâ”€â”€ carwashes.json          # Datos en JSON
â”œâ”€â”€ carwashes.xlsx          # Hoja de Excel
â”œâ”€â”€ carwashes.csv           # Archivo CSV
â”œâ”€â”€ insert_carwashes.sql    # Scripts SQL (deprecado)
â””â”€â”€ sample_carwashes.json   # Datos de muestra (primeros 5)
```

## ğŸ› ï¸ Desarrollo

### Agregar Nueva Fuente

1. Crea un nuevo archivo en `src/scrapers/`:

```typescript
// src/scrapers/mercadolibre.ts
export class MercadoLibreScraper {
  async scrape(): Promise<CarWashData[]> {
    // Tu lÃ³gica aquÃ­
  }
}
```

2. ImpÃ³rtalo en `src/index.ts`:

```typescript
import { MercadoLibreScraper } from './scrapers/mercadolibre';
```

3. AgrÃ©galo al flujo principal.

### Modificar BÃºsqueda

Edita `src/config.ts` para cambiar:
- Comuna objetivo
- Cantidad de resultados
- Delay entre requests

## ğŸ” Fuentes de Datos

### 1. Yapo.cl
- âœ… No requiere API key
- âœ… FÃ¡cil de scrapear
- âš ï¸ Datos limitados
- âš ï¸ Principalmente servicios independientes

### 2. Google Maps (API)
- âœ… Datos muy completos
- âœ… Ratings y reseÃ±as
- âœ… Coordenadas precisas
- âš ï¸ Requiere API key
- âš ï¸ LÃ­mite de requests

### 3. Google Maps (Puppeteer)
- âœ… No requiere API key
- âœ… Datos completos
- âš ï¸ MÃ¡s lento
- âš ï¸ Consume mÃ¡s recursos

## ğŸ“Š Ejemplo de Salida

```
ğŸš€ =============================================
ğŸš— ALTO CARWASH - SCRAPER DE AUTOLAVADOS
ğŸ“ RegiÃ³n: Metropolitana - Comuna: MaipÃº
===============================================

ğŸ“Œ 1. Scraping Yapo.cl...
âœ… Yapo: 12 autolavados encontrados

ğŸ“Œ 2. Scraping Google Places API...
âœ… Google: 28 autolavados encontrados

ğŸ“Š ============ RESUMEN ============
Total scrapeado: 40
Total Ãºnico: 35
Duplicados removidos: 5
=====================================

ğŸ’¾ Exportando datos...

âœ… Datos exportados a: output/carwashes.json
ğŸ“Š Total de registros: 35
âœ… Datos exportados a: output/carwashes.xlsx
ğŸ“Š Total de registros: 35
âœ… Datos exportados a: output/carwashes.csv
ğŸ“Š Total de registros: 35
âœ… SQL exportado a: output/insert_carwashes.sql
ğŸ“Š Total de registros: 35

âœ… Â¡Scraping completado exitosamente!
ğŸ“ Revisa la carpeta "output" para los archivos generados.
```

## ğŸ”„ ActualizaciÃ³n de Datos

Para mantener los datos actualizados:

```bash
# Ejecutar semanalmente
npm start

# O configurar cron job
0 0 * * 0 cd /path/to/scraper && npm start
```

## âš ï¸ Consideraciones Legales

- **Respeta los Terms of Service** de cada sitio
- **No sobrecargues los servidores** (usa delays apropiados)
- **Datos pÃºblicos solamente**
- **Uso educacional/comercial permitido**

## ğŸ› Troubleshooting

### Error: "Cannot find module"
```bash
npm install
```

### Error: "Google API quota exceeded"
- Espera 24 horas
- O usa `--puppeteer` en su lugar

### Error: "No data found"
- Verifica tu conexiÃ³n a internet
- Revisa que las URLs estÃ©n activas
- Chequea los selectores CSS (pueden cambiar)

## ğŸ“ TODO

- [ ] Agregar scraper de Facebook Marketplace
- [ ] Implementar scraper de Instagram
- [ ] Agregar detecciÃ³n automÃ¡tica de precios
- [ ] Implementar sistema de actualizaciÃ³n incremental
- [ ] Agregar validaciÃ³n de datos con IA

## ğŸ¤ Contribuir

Â¿Encontraste un bug o quieres agregar una feature?
1. Fork el proyecto
2. Crea tu branch (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios
4. Push y crea un Pull Request

## ğŸ“„ Licencia

MIT License - Uso libre para proyectos personales y comerciales.

---

**Desarrollado para Alto Carwash** ğŸš—âœ¨